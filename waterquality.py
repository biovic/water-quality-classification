# -*- coding: utf-8 -*-
"""WaterQuality.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nINF74eusNDokGgXpeC1_NXrR7p9Zfr2
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import csv

#only can be used in ipynb
# !git clone https://github.com/biovic/water-quality-classification
# !ls water-quality-classification/data

data_water=pd.read_csv("/home/biovick/Downloads/microsoft/assignment/last/pakistan_river.csv")
data_water.head()
# print(len(data_water))

num_of_chars=28
num_of_output=1
num_of_data=len(data_water)

print("number of data:" ,num_of_data)

counter_safe=0;
counter_unsafe=0;
total_safe_peril=[]
number_safety=[]


## PURPOSE: TO MAKE CSV DATA INTO QUANTIFIABLE, STRING ->BOOL
# dict_change={"7":"Un obj","8":"Clear","9":"O less","16":"BDL","25":"Nil","26":"Nil"}
# dict_change_keys= np.array(list(dict_change.keys()))
# dict_change_values= np.array(list(dict_change.values()))
# print(list(dict_change.values()))


for i in range(num_of_data):
  if(data_water.iloc[i,7]=="Un obj"):
    data_water.iloc[i,7]=0
  if(data_water.iloc[i,8]=="Clear"):
    data_water.iloc[i,8]=0
  if(data_water.iloc[i,9]=="O less" or data_water.iloc[i,9]=="Oless"):
    data_water.iloc[i,9]=0  
  if(data_water.iloc[i,10]=="BDL"):
    data_water.iloc[i,10]=0
  if(data_water.iloc[i,16]=="BDL" or data_water.iloc[i,16]==""):
    data_water.iloc[i,16]=0
  if(data_water.iloc[i,24]=="BDL"):
    data_water.iloc[i,24]=0
  if(data_water.iloc[i,25]=="Nil"):
    data_water.iloc[i,25]=0
  if(data_water.iloc[i,26]=="Nil"):
    data_water.iloc[i,26]=0

for j in range(5,num_of_chars-2):
  for i in range(num_of_data):
    A= np.array(data_water.iloc[i,j],dtype=np.float64)
    whereisNAN= np.isnan(A)
    A[whereisNAN]=0
    # print(A)
    data_water.iloc[i,j]=A

# print(data_water.head())
# print(data_water.iloc[2,23])

#output "safe"!= "Safe"
for i in range(num_of_data):
  if(data_water.iloc[i,num_of_chars-1]=='safe'):
    data_water.iloc[i,num_of_chars-1]='Safe'

  # A= np.array(data_water.iloc[i,24])
  # whereisNAN= np.isnan(A)
  # A[whereisNAN]=0
  # print(A)
  # data_water.iloc[i,24]=A

#determine amount of river safe or unsafe
for i in range (num_of_data):
  if(data_water.iloc[i,num_of_chars-1]=='Safe'):
    counter_safe=counter_safe+1
  else:
    counter_unsafe=counter_unsafe+1

total_safe_peril.append(counter_safe)
total_safe_peril.append(counter_unsafe)
print("Safe/Unsafe", total_safe_peril)

number_safety=[]
#make the amount into a dictionary to describe into graph bar
for i in range(num_of_data):
  if(data_water.iloc[i, num_of_chars-1]=='Safe'):
    number_safety.append(total_safe_peril[0])
  else:
    number_safety.append(total_safe_peril[1])

# #depict all the data into bar
plt.figure(figsize=(3, 4))
plt.bar(data_water.iloc[:,num_of_chars-1], number_safety)
plt.title("Data Water Safety in Pakistan river")
plt.xlabel("Safe/Unsafe")
plt.ylabel("Number of each category safety for Pakistan river")
plt.show()

myFile= open("/home/biovick/Downloads/microsoft/assignment/last/modified_pakistan_river.csv",'w')
with myFile:
    writer=csv.writer(myFile)
    writer.writerow(["No","Location","Owned by","Source","Depth","EC","pH","Taste","Color","Odor","Turb","Ca","Hard","Mg","Alk","HCO3","CO3","Cl","K","Na","NO3","SO4","TDS","F","As","Total Coliforms","E.Coli", "Safe/Unsafe"])
    for i in range(len(data_water)):
      data_water_perrow=[]
      for j in range(num_of_chars):
        data_water_perrow.append(data_water.iloc[i,j])
      writer.writerow(data_water_perrow)


#X, y
from sklearn.model_selection import train_test_split, cross_val_score

#decide X=characteristic water safety, Y=output safe or unsafe
X= data_water.iloc[:,5:num_of_chars-2]
y= data_water.iloc[:,num_of_chars-1]
print(X,y)

X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2)

print(X_train.shape)
print(y_train.shape)

# print(data_water.iloc[:,16])

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

all_score=[]
cv_scores=[]

#The model of SVM
model = SVC(kernel='linear', C=0.2, random_state=0)

#Training the model
model.fit(X_train,y_train)
y_result = model.predict(X_test)

#Error evaluation
score = accuracy_score(y_result, y_test)  #find the difference result between prediction and the truth
all_score.append(score)

print(all_score)
#Cross validation score
cross_validation= cross_val_score(model, X,y, cv=10)
print("SVM accuracy:  %0.3f (+/- %0.3f)" %(cross_validation.mean(), cross_validation.std()*2) )
result_cv_score= cross_validation.mean()
cv_scores.append(result_cv_score)

#plotting SVM algorithm to decide the accuracy
n=[]
for i in range (len(y_prediction)):
  n.append(i+1)

plt.plot(n, y_prediction)
plt.plot(n, y_result)
plt.title("Difference prediction and truth")
plt.xlabel("n")
plt.ylabel("output")
plt.legend(["y_test","y_predict"])
plt.show()


#using random forest
all_scores=[]
eval_scores=[]

from sklearn.ensemble import RandomForestClassifier

#Modelling 
model = RandomForestClassifier(random_state=0, n_estimators=25, n_jobs=2)
model.fit(X_train, y_train)

y_prediction= model.predict(X_test)

#Scoring system
score = accuracy_score(y_prediction,y_test)
all_scores.append(score)

#cross_validation score
cross_validation= cross_val_score(model, X,y, cv=10)
print("RF accuracy:  %0.3f (+/- %0.3f)" %(cross_validation.mean(), cross_validation.std()*2) )
result_cv_score= cross_validation.mean()
eval_scores.append(result_cv_score)

#plotting Random Forest algorithm to decide the accuracy
n=[]
for i in range (len(y_prediction)):
  n.append(i+1)

plt.plot(n, y_prediction)
plt.plot(n, y_result)
plt.title("Difference prediction and truth")
plt.xlabel("n")
plt.ylabel("output")
plt.legend(["y_test","y_predict"])
plt.show()


#KNN
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=100)

# Train the model using the training sets
model.fit(X_train,y_train)

#Predict Output
y_prediction= model.predict(X_test) # 0:Overcast, 2:Mild
# print(y_prediction)

#Scoring system
score = accuracy_score(y_prediction,y_test)
all_scores.append(score)

#cross_validation score
cross_validation= cross_val_score(model, X,y, cv=10)
print("RF accuracy:  %0.3f (+/- %0.3f)" %(cross_validation.mean(), cross_validation.std()*2) )
result_cv_score= cross_validation.mean()
eval_scores.append(result_cv_score)

#plotting KNN algorithm to decide the accuracy
n=[]
for i in range (len(y_prediction)):
  n.append(i+1)

plt.plot(n, y_prediction)
plt.plot(n, y_result)
plt.title("Difference prediction and truth")
plt.xlabel("n")
plt.ylabel("output")
plt.legend(["y_test","y_predict"])
plt.show()